org "openHABian %CONFIG"				# Organization name for reports
mailto "%ADMIN"						# Email address to receive reports
netusage 90000 Kbps					# Bandwidth limit, 90M
dumpcycle 14						# Backup cycle is 14 days
runspercycle 14						# Run 14 times within dumpcycle of 2 weeks
tapecycle %TAPES tapes					# Dump to this number of different tapes during the cycle
runtapes 10						# number of virtual containers to use at most per backup run
tpchanger %TPCHANGER
taper-parallel-write 2
autolabel "openHABian-%CONFIG-%%%" empty
tapelist "%CONFDIR/tapelist"				# The tapelist file
tapetype %TAPETYPE
infofile "/var/lib/amanda/%CONFIG/curinfo"		# Database directory
logdir "/var/log/amanda/%CONFIG"			# Log directory
indexdir "/var/lib/amanda/%CONFIG/index"		# Index directory
define tapetype SD {
    comment "SD card size"
    length 16 gbytes					# default SD card size (1 bucket = 1 SD d)
}
define tapetype DIRECTORY {				# Define our tape behaviour
	length %SIZE mbytes				# size of every virtual container (= max. usage per directory)
}
define tapetype AWS {
    comment "S3 Bucket"
    length %SIZE mbytes					# actual bucket size 5GB (Amazon default for free S3)
}

amrecover_changer "changer"				# Changer for amrecover

# don't use any holding disk for the time being
#holdingdisk hd {
#    directory "/holdingdisk/%CONFIG"
#    use 1000 Mb
#}

define application-tool app_amraw {			# how to dump the SD card's raw device /dev/mmcblk0
        plugin "amraw"					# uses 'dd'
}
define application-tool app_amgtar {
    plugin "amgtar"

    property        "NORMAL" ": socket ignored$"
    property append "NORMAL" "file changed as we read it$"
    property append "NORMAL" ": directory is on a different filesystem; not dumped$"
    property append "NORMAL" ": File removed before we read it$"

}
define dumptype global {				# The global dump definition
	maxdumps 2					# maximum number of backups run in parallel
	holdingdisk no					# Dump to temp disk (holdingdisk) before backup to tape
	index yes					# Generate index. For restoration usage
}
define dumptype amraw {
        global
        program "APPLICATION"
        application "app_amraw"
}
define dumptype comp-amraw {
        global
        program "APPLICATION"
        application "app_amraw"
	compress fast
}
define dumptype root-tar {				# How to dump root's directory
	global						# Include global (as above)
	program "GNUTAR"				# Program name for compress
	estimate server					# Estimate the backup size before dump
	comment "root partitions dumped with tar"
	compress none					# No compression
	index						# Index this dump
	priority low					# Priority level
}
define dumptype old-user-tar {				# How to dump user's directory
	root-tar					# Include root-tar (as above)
	comment "user partitions dumped with tar"
	priority medium					# Priority level
}
define dumptype comp-old-user-tar {			# How to dump & compress user's directory
	old-user-tar					# Include user-tar (as above)
	compress client fast				# Compress in client side with less CPU (fast)
}
define dumptype user-tar {                              # How to dump & compress user's directory
        global
        program "APPLICATION"
        application "app_amgtar"
        estimate server                                 # Estimate the backup size before dump
        comment "directories dumped with amgtar"
        index                                           # Index this dump
        priority medium                                 # Priority level
        compress client fast                            # Compress in client side with less CPU (fast)
}
# vim: filetype=conf
